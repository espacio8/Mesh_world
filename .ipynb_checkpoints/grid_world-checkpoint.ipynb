{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сеточный мир"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Постановка задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Условия: задана матрица состояний 5х5, функция ценности перехода из одного состояния в другое, $\\gamma = 0.9$. Стратегия выбора перехода (действия) - равновероятная."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача: для каждого состояния вычислить его ценность. Вычисления провести двумя методами: путём решения СЛАУ и методом Монте-Карло."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"mesh_world_problem.png\" width=600 height=600/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Решение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Монте-Карло"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим функцию, которая делает броски по Монте-Карло и для перехода из одного состояния в другое пользуется предоставленной стратегией.\n",
    "\n",
    "Стратегия - это функция, которая принимает на вход текущее состояние и возвращает следующее состояние и награду за переход в следующее состояние."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Tuple\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def mc_solution(\n",
    "        strategy: Callable[[int, int], Tuple[int, int, float]],\n",
    "        width: int=5, \n",
    "        height: int=5, \n",
    "        gamma: float=0.9, \n",
    "        exp_cnt: int=10**6\n",
    "    ):\n",
    "    '''\n",
    "    Monte-Carlo based solution. Model `exp_cnt` experiments, extract average out of results.\n",
    "    Arguments:\n",
    "    * width, height - size of statuses' matrix.\n",
    "    * gamma - decay coefficient.\n",
    "    * exp_cnt - number of experiments per state.\n",
    "    * strategy - callable object, which accepts current state (starting from (1,1)) and returns next state (also starting from (1,1))\n",
    "and reward for passing to this state.\n",
    "    \n",
    "    Returns numpy.ndarray of size height*width, which elements are value function of corresponding state.\n",
    "    '''\n",
    "    def _make_throw(i, j, gamma, gamma_i = -1):\n",
    "        eps = 10**(-20)\n",
    "        result_i = 0.\n",
    "        gamma_i = gamma if gamma_i == -1 else gamma_i\n",
    "        \n",
    "        next_i, next_j, reward = strategy(i, j)\n",
    "        result_i += reward\n",
    "        if gamma_i >= eps:\n",
    "            result_i += gamma_i * _make_throw(next_i, next_j, gamma, gamma_i*gamma)\n",
    "        \n",
    "        return result_i\n",
    "    \n",
    "    result = np.zeros((height, width))\n",
    "    \n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            total_value = 0.\n",
    "            \n",
    "            for _ in range(exp_cnt):\n",
    "                total_value += _make_throw(i+1, j+1, gamma)\n",
    "            result[i,j] = total_value / exp_cnt\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим стратегию, которая соответствует нашей задаче."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def strategy(i: int, j: int):\n",
    "    possible_states = [\n",
    "        (i+1, j),\n",
    "        (i-1, j),\n",
    "        (i, j+1),\n",
    "        (i, j-1)\n",
    "    ]\n",
    "    reward = 0.\n",
    "    \n",
    "    next_state = possible_states[np.random.randint(0, len(possible_states))]\n",
    "    \n",
    "    # Check for special states.\n",
    "    if i == 1 and j == 2:\n",
    "        next_state = (5,2)\n",
    "        reward = 10.\n",
    "    elif i == 1 and j == 4:\n",
    "        next_state = (3,4)\n",
    "        reward = 5.\n",
    "        \n",
    "    # Check if we are out of grid.\n",
    "    if next_state[0] < 1 or next_state[0] > 5 or \\\n",
    "       next_state[1] < 1 or next_state[1] > 5:\n",
    "        next_state = (i,j)\n",
    "        reward = -1.\n",
    "    \n",
    "    return *next_state, reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.80139515  9.41983516  4.54353174  5.10241533  0.9700123 ]\n",
      " [ 1.36944605  2.95182404  1.36515031  1.24760696 -0.0186247 ]\n",
      " [-0.23637236  0.20362285  0.22714912  0.48405759 -0.41205169]\n",
      " [-0.7493346  -0.29791078 -0.1662934  -0.2691216  -0.86678921]\n",
      " [-1.23336684 -0.76277585 -0.85732181 -0.99532201 -1.30354217]]\n"
     ]
    }
   ],
   "source": [
    "print(mc_solution(strategy, exp_cnt=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.73344995e+00  9.34575208e+00  4.00785152e+00  5.10829236e+00\n",
      "   1.00348144e+00]\n",
      " [ 7.58619585e-01  2.71877974e+00  1.57223010e+00  1.50643567e+00\n",
      "  -7.74246549e-03]\n",
      " [-4.15810115e-01  4.23875064e-01  3.57277092e-01  1.28258183e-01\n",
      "  -5.48568546e-01]\n",
      " [-7.89485036e-01 -2.35076193e-01 -1.93303972e-01 -3.40621184e-01\n",
      "  -8.85231326e-01]\n",
      " [-1.37351778e+00 -9.08097047e-01 -7.76913434e-01 -8.78539587e-01\n",
      "  -1.34956990e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(mc_solution(strategy, exp_cnt=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.85357028  9.32852835  4.0004718   5.10245232  0.94855464]\n",
      " [ 0.77533485  2.58388212  1.63078069  1.43364655  0.05412706]\n",
      " [-0.33218977  0.42994241  0.32803727  0.15303313 -0.51903862]\n",
      " [-0.79856469 -0.2924005  -0.21003864 -0.33830301 -0.85233398]\n",
      " [-1.36156277 -0.89249412 -0.77310798 -0.8959561  -1.35860484]]\n"
     ]
    }
   ],
   "source": [
    "print(mc_solution(strategy, exp_cnt=10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Решение методом Монте-Карло значительно расходится с реальным. Кажется, это можно списать на стохастическую природу метода - можно заметить, как в зависимости от количества бросков меняется финальный результат."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Решение СЛАУ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы знаем следующее: $\\nu_{\\pi}(s) = \\sum_{a}{\\pi(a|s)}\\sum_{s'}\\sum_{r}p(s',r|s,a)[r + \\gamma\\nu_{\\pi}(s')]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наша стратегия - равновероятная, поэтому $\\pi(a|s) = 1/4$ для обычных клеток (всего четыре различных действия), $\\pi(a|s) = 1$ для клеток A и B (в них мы можем сделать только одно конкретное действие).\n",
    "\n",
    "Также нам известно, что при любом действии у нас возможно только одно вознаграждение и переход в одно конкретное состояние."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, изначальная формула преобразуется в \n",
    "\n",
    "$\\nu_{\\pi}(s) = \\begin{cases} \\sum_{a}\\frac{1}{4}(r_{a} + \\gamma\\nu_{\\pi}(s'_{a})), & s \\notin \\{A,B\\} \\\\ r + \\gamma\\nu_{\\pi}(s'), & s \\in \\{A,B\\} \\end{cases}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подставив в формулу каждое состояние $s$, получим СЛАУ, решив которую, мы получим искомые стоимости.\n",
    "\n",
    "Формула выше в матричном виде будет иметь вид $Ax + b = x$, \n",
    "\n",
    "где $b = (\\sum_{a_{s_{1}}}\\frac{1}{4}r_{a_{s_{1}}} \\dots \\sum_{a_{s_{n}}}\\frac{1}{4}r_{a_{s_{n}}})^{T}$ - вектор свободных членов, которые являются матожиданием награды в соответствующих состояниях,\n",
    "\n",
    "$a_{ij} = \\begin{cases} \\sum{\\frac{\\gamma}{4}}, & \\mbox{если из состояния } s_{i} \\mbox{ можно перейти в состояние } s_{j} \\mbox{ и } s_{i} \\notin \\{A,B\\} \\mbox{. Сумма считается по всем действиям, в результате которых из состояния } s_{i} \\mbox{ достигается состояние } s_{j}, \\\\ \\gamma, & \\mbox{если из состояния } s_{i} \\mbox{ можно перейти в состояние } s_{j} \\mbox{ и } s_{i} \\in \\{A,B\\}, \\\\ 0, & \\mbox{иначе.} \\end{cases}$,\n",
    "\n",
    "$x$ - вектор $\\nu_{\\pi}(s)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразовав это уравнение, получим $(A-E)x = -b$, \n",
    "\n",
    "оно же $(E - A)x = b$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для решения, как и раньше, заведём две отдельные функции. На этот раз одна функция определяет стратегию, строит матрицу и решает СЛАУ, а вторая по заданным координатам генерирует все возможные действия с наградами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Generator, Tuple\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def system_solution(\n",
    "        action_generator: Callable[[int, int], Generator[Tuple[int, int, float], None, None]],\n",
    "        n: int=5,\n",
    "        m: int=5,\n",
    "        gamma: float=0.9\n",
    "    ):\n",
    "    n,m = 5,5\n",
    "    a = np.eye(n*m)\n",
    "    b = np.zeros(n*m)\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            current_state = i*m + j\n",
    "            states_to_update = dict()\n",
    "            \n",
    "            for state_info in action_generator(i+1, j+1):\n",
    "                next_state = (state_info[0]-1)*m + (state_info[1]-1)\n",
    "                reward = state_info[2]\n",
    "                \n",
    "                if next_state in states_to_update:\n",
    "                    states_to_update[next_state] += 1\n",
    "                else:\n",
    "                    states_to_update[next_state] = 1\n",
    "                b[current_state] += reward\n",
    "                \n",
    "            states_cnt = sum(states_to_update[state] for state in states_to_update)\n",
    "            for state in states_to_update:\n",
    "                for _ in range(states_to_update[state]):\n",
    "                    a[current_state, state] -= gamma / states_cnt\n",
    "    \n",
    "    result = np.linalg.solve(a, b)\n",
    "    result.resize((n,m))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def action_generator(i: int, j: int):\n",
    "    possible_states = [\n",
    "        (i+1, j),\n",
    "        (i-1, j),\n",
    "        (i, j+1),\n",
    "        (i, j-1)\n",
    "    ]\n",
    "    \n",
    "    if i == 1 and j == 2:\n",
    "        yield 5, 2, 10.\n",
    "    elif i == 1 and j == 4:\n",
    "        yield 3, 4, 5.\n",
    "    else:\n",
    "        for state in possible_states:\n",
    "            reward = 0.\n",
    "            \n",
    "            if state[0] < 1 or state[0] > 5 or \\\n",
    "               state[1] < 1 or state[1] > 5:\n",
    "                state = (i,j)\n",
    "                reward = -1. / 4\n",
    "                \n",
    "            yield *state, reward\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.30899634  8.78929186  4.42761918  5.32236759  1.49217876]\n",
      " [ 1.52158807  2.99231786  2.25013995  1.9075717   0.54740271]\n",
      " [ 0.05082249  0.73817059  0.67311326  0.35818621 -0.40314114]\n",
      " [-0.9735923  -0.43549543 -0.35488227 -0.58560509 -1.18307508]\n",
      " [-1.85770055 -1.34523126 -1.22926726 -1.42291815 -1.97517905]]\n"
     ]
    }
   ],
   "source": [
    "print(system_solution(action_generator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Решение методом решения СЛАУ прекрасно сошлось с ожидаемым!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
